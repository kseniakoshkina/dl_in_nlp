{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0fOWhqwW-AT",
        "outputId": "fd9b0ab0-83f0-4cc4-a83b-b86e3649334b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wugeOHW-AV",
        "outputId": "2a1e3e43-a45f-447e-8426-d1ee68512228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XIrxSmW-AX"
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1FB3IBW-AY",
        "outputId": "31ca21a0-3383-4376-ef90-c0496d4c4b1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-16 08:21:21--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M   129MB/s    in 0.2s    \n",
            "\n",
            "2021-12-16 08:21:22 (129 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwE7AA8B4WXK",
        "outputId": "8205ead6-f8e0-479a-b2a9-653ec6bf7621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-16 08:23:22--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G  30.4MB/s    in 41s     \n",
            "\n",
            "2021-12-16 08:24:03 (30.2 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BWA7IClKW-Aa"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJpFTPpsW-Ac",
        "outputId": "77d99a99-04ec-4d57-dde4-cdc44137727b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 168236\n",
            "-rw-r--r-- 1 root root  28717126 Dec 16 08:21 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 143546925 Dec 16 08:21 cc.ru.300.vec.gz\n",
            "drwxr-xr-x 1 root root      4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qmzaEwy9W-Ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BbDKxq4EW-Ag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "hcAdsbS7W-Ai",
        "outputId": "95c0daf6-28fa-4814-ab3d-23adf4e09f49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tXLjfsW-Aj",
        "outputId": "3fef62c3-a7f8-4e9d-ab93-d06bab2220a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHbifWIW-Al"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJcT1qPZW-An",
        "outputId": "cf1941f4-ccdd-4ddf-f791-4a7161f52d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 168236\n",
            "-rw-r--r-- 1 root root  28717126 Dec 16 08:21 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 143546925 Dec 16 08:21 cc.ru.300.vec.gz\n",
            "drwxr-xr-x 1 root root      4096 Dec  3 14:33 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "M0lwyZUFW-Ap"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QQpX51Y4W-Aq"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "    \n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "    \n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyI2erCDW-Ar",
        "outputId": "56104016-c433-4601-dcea-8df774231ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 237779/237779 [00:07<00:00, 33904.68it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "    \n",
        "    words = process_text(text)\n",
        "    \n",
        "    lengths.append(len(words))\n",
        "    \n",
        "    for word in words:\n",
        "        \n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FGzDm0ptW-At"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "iZBR-aYDW-Av",
        "outputId": "1909729d-d71a-4e7a-a52b-235b479a29a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fbb32b9cb90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OBzmPqXIW-Aw",
        "outputId": "da1c6d1a-5017-44e9-aa83-63c06fd6c7fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths \n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSer_0bW-Ay",
        "outputId": "234af8c7-e8e8-4df6-8450-568acb8dfa59"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "szg6XD3EW-Az",
        "outputId": "e9b3186d-402b-4549-d738-f1394384de95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbOg0FqW-A1"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "T1Yx_qr-W-A2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEgfnaWW-A4",
        "outputId": "973bacc4-fa72-4d43-b99a-37bb3e88c4c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:12<00:00, 27740.79it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "    \n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "    \n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "        \n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AYJMzgpnW-A7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04261361-70ee-4dbd-c364-9bf5cec02ac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KE06fafiW-A8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26357684-fdaa-4751-e8d7-37c399730c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFPNApUjW-A9"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_fo1fB6JW-A-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKAjCg3W-BA"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "D19pDyQBW-BA"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Yxsxr7edW-BB"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "TZy0lKr2W-BC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00ebf458-50e6-4814-cb43-01adcf603be2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 loop, best of 5: 858 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s611e34SW-BE"
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xjFlWdgtW-BE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07211b87-7c20-456b-c45d-f640465f1eaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jaMMD5CDW-BG"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GeQCiSYdW-BH"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "S_qUdMcbW-BJ"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hSUQmRgtW-BK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b17a6c9-d12a-42dd-ff35-ffd6a18b3159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 30.2 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPvqNWkQW-BM"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FaPKGO5aW-BN"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NX5HHDOW-BO"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKr22rklW-BP"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "vc-bLok2W-BQ"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OHpit-1tW-BR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f0f1f6-94ab-4cfa-cd1c-eb726bebba7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ru_WzGSJW-BS"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "NHdBavTWW-BT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a36aa13d-a2e1-4975-840e-d6e068e00321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Rcxv55j7W-BV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f488224-1ba4-4778-b30e-82e68e8ee564"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJt6cqkW-BW"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyM8Xl24W-BX",
        "outputId": "76fb33df-fa2d-4b1c-97d5-e90ad41a7780"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPNMjEZW-BY"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "btJ-ApiOW-BY"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "QIYff7YyW-Bb"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "7tVn6YKLW-Bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45339bdd-3f5e-4400-c74e-c154adfb7926"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2N4w6-iWW-Be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2273f0c-1e0d-455a-8d81-cf3c5c47a773"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "7-C3_phaW-Bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099a0d0d-1770-460f-de0d-08239234fee7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "vPX_m5M4W-Bi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "hV76BdN0W-Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3902275b-7205-4782-bd9a-7fa91bfc97b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "INB_dPAnW-Bk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e6f76c9d-630d-41d6-9370-21b5a82d4c74"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "iHeFzZe1W-Bl"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "X3x9QhXYW-Bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45086b82-3f0c-4312-c0b6-1029b1c27116"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'business': 0, 'food': 4, 'law': 1, 'love': 2, 'relax': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ef--8SWbW-Bo"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc48ALg_W-Bp"
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIQEv6nvE4c"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "lBrihzIT4Rj-"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMyJSEpeLtt_",
        "outputId": "83e7954c-374b-4ace-e58b-e98a60c85a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('russian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "ZkX8SC_sW-Bp"
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "    \n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "        \n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "        \n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "        \n",
        "        self.load(x_data, verbose=verbose)\n",
        "        \n",
        "    @staticmethod\n",
        "    def process_text(text):\n",
        "\n",
        "        \n",
        "        # Место для вашей предобработки\n",
        "        \n",
        "        words = wordpunct_tokenize(text.lower())\n",
        "        #words = re.findall('[a-яА-ЯеЁ]+', text.lower())\n",
        "        '''filtered_tokens = []\n",
        "        for token in words:\n",
        "          if token not in stop_words:\n",
        "              filtered_tokens.append(token)'''\n",
        "        return words\n",
        "        \n",
        "    def load(self, data, verbose=True):\n",
        "        \n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "        \n",
        "        for text in data_iterator:\n",
        "            \n",
        "            words = self.process_text(text)\n",
        "            \n",
        "            indexed_words = self.indexing(words)\n",
        "            \n",
        "            self.x_data.append(indexed_words)\n",
        "    \n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "        \n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "    \n",
        "    def padding(self, sequence):\n",
        "        \n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.x_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "        \n",
        "        y = self.y_data[idx]\n",
        "        \n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "R3WW8V9lyLm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnc2nD8gW-Br",
        "outputId": "dd605b89-f4f8-4a7f-817b-9573fbb19835"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:03<00:00, 69746.73it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:00<00:00, 50284.78it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "dGeftxdgW-Br"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkGQffBW-Bs",
        "outputId": "ba9a170b-644d-41c1-9751-8f223c0412c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  3989,      1,     24,  ...,      0,      0,      0],\n",
              "        [ 33284,     13,   2932,  ...,      0,      0,      0],\n",
              "        [   593,    700,      7,  ...,      0,      0,      0],\n",
              "        ...,\n",
              "        [    26,     66,   4182,  ...,      0,      0,      0],\n",
              "        [  1042,     10, 104393,  ...,      0,      0,      0],\n",
              "        [    24,   1107,    122,  ...,      0,      0,      0]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUk4nGcW-Bt",
        "outputId": "3baee785-dac7-4a96-aa61-3530c99adfa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 1, 4, 3, 3, 2, 0, 4, 1, 0, 2, 4, 3, 4, 2, 1, 3, 4, 1, 1, 2, 1, 2,\n",
              "        1, 4, 4, 2, 4, 1, 4, 3, 4, 2, 4, 3, 1, 1, 1, 4, 3, 0, 3, 2, 3, 0, 4, 0,\n",
              "        0, 3, 3, 1, 4, 3, 1, 0, 1, 0, 0, 0, 1, 2, 0, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "WlhDV2fm4Rj_"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math as math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "3wwkxZm1vE43"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "    def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "        self.num_layers = 2\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "        self.LSTM = torch.nn.LSTM(300, 256, num_layers=self.num_layers, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        \n",
        "        self.q_proj = nn.Linear(in_features=512, out_features=256)\n",
        "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.k_proj = nn.Linear(in_features=512, out_features=256)\n",
        "        self.v_proj = nn.Linear(in_features=512, out_features=256)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        \n",
        "        self.cnn_3gr = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, padding='same')\n",
        "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_4gr = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=4, padding='same')\n",
        "        self.cnn_5gr = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=5, padding='same')\n",
        "\n",
        "        self.linear_1 = nn.Linear(in_features=384, out_features=256)# сверху накидываем два полносвязных слоя для классификации\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=n) \n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x_emb = self.emb_layer(x)#примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "        x_emb = x_emb.transpose(0, 1)\n",
        "        x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "        x = x.transpose(0, 1)\n",
        "        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "        x_k = self.k_proj(x)\n",
        "        x_v = self.v_proj(x)\n",
        "\n",
        "        att_scores = torch.bmm(x_q, x_k.transpose(1, 2)) / math.sqrt(x.shape[-1]) \n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "        attention_vectors = torch.bmm(att_dist, x_v)# тут тоже что то с чем то нужно перемножить :)\n",
        "        x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "        x_cnn3 = self.cnn_3gr(x_att)\n",
        "        x_cnn4 = self.cnn_4gr(x_att)\n",
        "        x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "        frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "        sc, _ = x_cnn4.max(dim= -1,)\n",
        "        thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "        x = self.linear_1(x_cat)# пару полносвязных слоев с релу для классификации\n",
        "        x = self.relu(x)    \n",
        "        x = self.linear_2(x)\n",
        "    \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "jFbyUXLE0WPv"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "OZgh4ONx0HvT"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO6VSbJgQ36",
        "outputId": "508793df-09ac-41a3-c9fc-053e1aa7785c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=same)\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,), padding=same)\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(5,), stride=(1,), padding=same)\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "E66MWNgM0QKM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9740fd62-c8d0-4317-98e7-4dfeb145fb9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py:298: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at  ../aten/src/ATen/native/Convolution.cpp:647.)\n",
            "  self.padding, self.dilation, self.groups)\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErboeQbv0dnC",
        "outputId": "063eaac5-3017-4c03-81fb-596c7e3d74f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "bL6zIZSt0h9W"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Vsxw4M2m0m2B"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rUTc0l60pV9",
        "outputId": "34fb5839-4b1a-4579-e495-08d695319e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [04:40<00:00, 762.79it/s, train_loss=0.493]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.623, test - 0.487\n",
            "F1 test - 0.823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [04:41<00:00, 761.07it/s, train_loss=0.461]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.470, test - 0.472\n",
            "F1 test - 0.829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [04:41<00:00, 759.50it/s, train_loss=0.441]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.448, test - 0.463\n",
            "F1 test - 0.832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [04:42<00:00, 757.22it/s, train_loss=0.421]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.429, test - 0.459\n",
            "F1 test - 0.834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 214001/214001 [04:41<00:00, 759.24it/s, train_loss=0.399]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.408, test - 0.466\n",
            "F1 test - 0.834\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMaPbh3oWwc"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "_aPjTQcR0vm2"
      },
      "outputs": [],
      "source": [
        "for instance in list(tqdm._instances): \n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_TOPGUR4RkA"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "e5BgHdtW2sO3"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att2(torch.nn.Module):\n",
        "    def __init__(self, matrix_w, n): #n - количетсво категорий\n",
        "        \n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "        self.num_layers = 1\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "        self.LSTM = torch.nn.LSTM(300, 256, num_layers=self.num_layers, batch_first=True, dropout=0.1, bidirectional=True)\n",
        "        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        \n",
        "        self.q_proj = nn.Linear(in_features=512, out_features=256)\n",
        "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.k_proj = nn.Linear(in_features=512, out_features=256)\n",
        "        self.v_proj = nn.Linear(in_features=512, out_features=256)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "        \n",
        "        self.cnn_3gr = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=2, stride=1)\n",
        "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_4gr = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=3, stride=1)\n",
        "        self.cnn_5gr = nn.Conv1d(in_channels=256, out_channels=128, kernel_size=4, stride=1)\n",
        "\n",
        "        self.linear_1 = nn.Linear(in_features=384, out_features=256)# сверху накидываем два полносвязных слоя для классификации\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(in_features=256, out_features=128) \n",
        "        self.linear_3 = torch.nn.Linear(in_features=128, out_features=64) \n",
        "        self.linear_4 = torch.nn.Linear(in_features=64, out_features=n) \n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "         \n",
        "    def forward(self, x):\n",
        "        x_emb = self.emb_layer(x)#примените эмбеддинги\n",
        "      # транспонируйте тензор для лстм как было описано выше\n",
        "        x_emb = x_emb.transpose(0, 1)\n",
        "        x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      # транспонируйте обратно\n",
        "        x = x.transpose(0, 1)\n",
        "        x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "        x_k = self.k_proj(x)\n",
        "        x_v = self.v_proj(x)\n",
        "\n",
        "        att_scores = torch.bmm(x_q, x_k.transpose(1, 2)) / math.sqrt(x.shape[-1]) \n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "        att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "        attention_vectors = torch.bmm(att_dist, x_v)# тут тоже что то с чем то нужно перемножить :)\n",
        "        x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "        x_cnn3 = self.cnn_3gr(x_att)\n",
        "        x_cnn4 = self.cnn_4gr(x_att)\n",
        "        x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "        frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "        sc, _ = x_cnn4.max(dim= -1,)\n",
        "        thr, _ = x_cnn5.max(dim= -1,)\n",
        "      \n",
        "        x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "        x = self.linear_1(x_cat)# пару полносвязных слоев с релу для классификации\n",
        "        x = self.relu(x)    \n",
        "        x = self.linear_2(x)\n",
        "        x = self.relu(x)    \n",
        "        x = self.linear_3(x)\n",
        "        x = self.relu(x)    \n",
        "        x = self.linear_4(x)\n",
        "    \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "WVMBFVL2WeLU"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "NjHgNnTihE8v"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "1Z4uhHa_Wegl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae9d52e4-b86d-47b1-f779-544ae3b2ac79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        }
      ],
      "source": [
        "model2 = model_with_att2(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "wItMl4NLWu5K"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model2.parameters(),lr=0.003)\n",
        "model2 = model2.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "CFkBi43XWoU7"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model2(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "7CFOj4kkWn2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81984630-8ec3-4959-9e6d-9de0b191c3ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_with_att2(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 256, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (k_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (v_proj): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(256, 128, kernel_size=(2,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(256, 128, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(256, 128, kernel_size=(4,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=384, out_features=256, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=256, out_features=128, bias=True)\n",
              "  (linear_3): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear_4): Linear(in_features=64, out_features=5, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "source": [
        "model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "2_QjfmSqWrmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66785eaf-8792-4b73-bb10-209885f5427f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([34, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "-fZ5pUq-Ws8R"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "uz1cw368WxM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37494f5-d8d9-4595-c0b0-137c0d55ca8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 214001/214001 [02:21<00:00, 1508.11it/s, train_loss=0.502]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.595, test - 0.517\n",
            "F1 test - 0.816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 214001/214001 [02:21<00:00, 1510.64it/s, train_loss=0.462]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.472, test - 0.494\n",
            "F1 test - 0.820\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 214001/214001 [02:22<00:00, 1501.69it/s, train_loss=0.437]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.444, test - 0.478\n",
            "F1 test - 0.833\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 214001/214001 [02:23<00:00, 1492.89it/s, train_loss=0.414]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Losses: train - 0.422, test - 0.491\n",
            "F1 test - 0.826\n",
            "Early stopping\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "    \n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "    \n",
        "    model2.train()\n",
        "    \n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        pred = model2(x)\n",
        "        loss = criterion(pred, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "        \n",
        "    progress_bar.close()\n",
        "    \n",
        "    model2.eval()\n",
        "    \n",
        "    for x, y in validation_loader:\n",
        "        \n",
        "        x = x.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model2(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "        \n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "    \n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "        \n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В общем, как бы я не пыталась, улучшить модель почему-то не получилось. Возможно, недостаточно пыталась, но перепробовала множество вариантов: и увеличение слоев, и изменение параметров кернела и шага в свертках, и изменение оптимизатора, и добавление дропаута. Либо модель переобучалась, либо лосс не падал и f1 score не увеличивался."
      ],
      "metadata": {
        "id": "5g0ianW60l8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "A5RyCFT1KOb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2720e867-955b-4419-d8bc-27cef82c7f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 32.6 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.3 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 21.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 483 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "O4D1xoZzLGhM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d998fa-533f-424e-9f99-2995b81b28b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-16 10:21:21--  https://github.com/thedenaas/hse_seminars/raw/master/2019/exam/exam_data.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2019/exam/exam_data.zip [following]\n",
            "--2021-12-16 10:21:21--  https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2019/exam/exam_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7356841 (7.0M) [application/zip]\n",
            "Saving to: ‘exam_data.zip’\n",
            "\n",
            "exam_data.zip       100%[===================>]   7.02M  44.9MB/s    in 0.2s    \n",
            "\n",
            "2021-12-16 10:21:21 (44.9 MB/s) - ‘exam_data.zip’ saved [7356841/7356841]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/thedenaas/hse_seminars/raw/master/2019/exam/exam_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip exam_data.zip"
      ],
      "metadata": {
        "id": "e4JhE4wUF1yB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ff96f76-5f57-40ea-8caf-68f60692690a"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  exam_data.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "ru5Gp6JGF554",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ff2c12-33a4-4305-85d9-faf0b9d06a49"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "answers_subsample.csv  exam_data.zip  test.csv\n",
            "cc.ru.300.vec\t       sample_data    train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')\n",
        "\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df_train.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df_train.sample(10)"
      ],
      "metadata": {
        "id": "rzUVJKckF_3s",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "fc0e540a-c2e7-4019-8420-defaac4b40f4"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 48,192\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>title</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22970</th>\n",
              "      <td>En general muy bien</td>\n",
              "      <td>Es un Hotel maravilloso,que siempre me ha gustado</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45758</th>\n",
              "      <td>Excellent service.</td>\n",
              "      <td>Okay as it goes</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43177</th>\n",
              "      <td>Location was great for sightseeing. Neighborho...</td>\n",
              "      <td>sightseeing getaway</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43073</th>\n",
              "      <td>Read the reviews and agree that if you are loo...</td>\n",
              "      <td>Hotel Diva - clean and friendly</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10715</th>\n",
              "      <td>The beds were hard, the rooms had an odd odor ...</td>\n",
              "      <td>No frilly but clean and reasonable</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9800</th>\n",
              "      <td>Other than not receiving an extra blanket we h...</td>\n",
              "      <td>Lovely hotel</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>The way we came in, it was a little off the be...</td>\n",
              "      <td>Great for the price!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10730</th>\n",
              "      <td>Wanted to check out their wine tasting, the wi...</td>\n",
              "      <td>Great Location</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26618</th>\n",
              "      <td>It was great!</td>\n",
              "      <td>My Holiday Inn Stay</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12295</th>\n",
              "      <td>The quality of this hotel was outstanding. Eve...</td>\n",
              "      <td>Nicest Hotel I've Ever Stayed In</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  ... target\n",
              "22970                                En general muy bien  ...      5\n",
              "45758                                 Excellent service.  ...      5\n",
              "43177  Location was great for sightseeing. Neighborho...  ...      3\n",
              "43073  Read the reviews and agree that if you are loo...  ...      3\n",
              "10715  The beds were hard, the rooms had an odd odor ...  ...      2\n",
              "9800   Other than not receiving an extra blanket we h...  ...      4\n",
              "1716   The way we came in, it was a little off the be...  ...      4\n",
              "10730  Wanted to check out their wine tasting, the wi...  ...      4\n",
              "26618                                      It was great!  ...      5\n",
              "12295  The quality of this hotel was outstanding. Eve...  ...      5\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLvwY1-IyRgY",
        "outputId": "89a60f44-f653-4f35-a9f5-4876795cbdc3"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [00:10<00:00, 19696.77it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [00:01<00:00, 21493.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UlzF6iV1yV60",
        "outputId": "3d0c6793-2af0-4fc3-b0b4-38415733b184"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>3</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>1</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>4</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>4</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>0</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0              0  Могут ли в россельхозбанке дать в залог норков...\n",
              "1              1  Может ли срочник перевестись на контракт после...\n",
              "2              0  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3              0  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4              1                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774         3                                  елку нарядили? =)\n",
              "237775         1  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776         4  Попробовала варить рис с половиной кубика для ...\n",
              "237777         4  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778         0  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "num_chunks = 2\n",
        "np.array_split(data,num_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSoAPOU63Vif",
        "outputId": "f6babdf4-ac56-4556-db96-3496070ac7d6"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[        category                                               text\n",
              " 0              0  Могут ли в россельхозбанке дать в залог норков...\n",
              " 1              1  Может ли срочник перевестись на контракт после...\n",
              " 2              0  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              " 3              0  В чем смысл криптовалюты, какая от неё выгода ...\n",
              " 4              1                 часть 1 статья 158 похитил телефон\n",
              " ...          ...                                                ...\n",
              " 118885         3          Что будет если выпить 6 таблеток кофеина?\n",
              " 118886         3  почему Николая Баскова называют \" золотой голо...\n",
              " 118887         1  Пособие по беременности и родам для неработающ...\n",
              " 118888         1  Месяц назад, ночью, на пешеходном переходе сби...\n",
              " 118889         1          Чем грозит невыполнение предписания суда?\n",
              " \n",
              " [118890 rows x 2 columns],\n",
              "         category                                               text\n",
              " 118890         1                Служебное жилье. Как оставить себе?\n",
              " 118891         1  Можно ли пересечь границу в Казахстан если нет...\n",
              " 118892         2  Я в игре призвал Пегаса с помощью магического ...\n",
              " 118893         3                           Фильм \"Всегда говори да\"\n",
              " 118894         1    элементы, составляющие статус депутата и дальше\n",
              " ...          ...                                                ...\n",
              " 237774         3                                  елку нарядили? =)\n",
              " 237775         1  Имеется переработка при 75% ставки, отгулы не ...\n",
              " 237776         4  Попробовала варить рис с половиной кубика для ...\n",
              " 237777         4  Почему рекоменд... Почему рекомендуют есть фру...\n",
              " 237778         0  Подскажите какие риски бывают в семье среднест...\n",
              " \n",
              " [118889 rows x 2 columns]]"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data,data2 = np.array_split(data,num_chunks)"
      ],
      "metadata": {
        "id": "bPo5T60l3X-A"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = data.text.values\n",
        "labels = data.category.values"
      ],
      "metadata": {
        "id": "1Ej4z-NCGGvt"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "Qz0KEuBYGJfp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e8ca01-40f2-4eb5-94b5-1d0828c9859d"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "metadata": {
        "id": "BeG1JhOVGOHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568ba064-2ea7-43cb-8aee-efbe1ce17e3d"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Tokenized:  ['могут', 'ли', 'в', 'рос', '##сель', '##хо', '##з', '##бан', '##ке', 'да', '##ть', 'в', 'зал', '##ог', 'но', '##рк', '##овых', 'ш', '##уб', 'пом', '##оги', '##те', 'по', '##жал', '##уи', '##ста']\n",
            "Token IDs:  [22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "\n",
        "                        # This function also supports truncation and conversion\n",
        "                        # to pytorch tensors, but we need to do padding, so we\n",
        "                        # can't use these features :( .\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "qt_5vQgSGtNX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c1a217-4ec6-411a-f6da-b9d740aa01b7"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Могут ли в россельхозбанке дать в залог норковых шуб помогите пожалуйста\n",
            "Token IDs: [101, 22553, 23029, 309, 26673, 80686, 37489, 11637, 42572, 11827, 10448, 11569, 309, 53932, 19820, 11299, 53464, 20565, 330, 58675, 86074, 60338, 10740, 10291, 28704, 62848, 15294, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "metadata": {
        "id": "gZFXeZUwGvnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "979c702c-d01b-4b91-a208-9b4b48e47869"
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll borrow the `pad_sequences` utility function to do this.\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Set the maximum sequence length.\n",
        "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
        "# maximum training sentence length of 47...\n",
        "MAX_LEN = 70\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "# Pad our input tokens with value 0.\n",
        "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
        "# as opposed to the beginning.\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AexaJn2O1UkI",
        "outputId": "424708af-f038-4efe-836d-1140e531f962"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 70 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# For each sentence...\n",
        "for sent in input_ids:\n",
        "    \n",
        "    # Create the attention mask.\n",
        "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
        "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    \n",
        "    # Store the attention mask for this sentence.\n",
        "    attention_masks.append(att_mask)"
      ],
      "metadata": {
        "id": "0JmjVo4B1Zzd"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lHAaHNok3EYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use train_test_split to split our data into train and validation sets for\n",
        "# training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use 90% for training and 10% for validation.\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "# Do the same for the masks.\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "metadata": {
        "id": "W5Lh2w0w1cUd"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert all inputs and labels into torch tensors, the required datatype \n",
        "# for our model.\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "metadata": {
        "id": "sAYrRnfl1en2"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here.\n",
        "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
        "# 16 or 32.\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader for our training set.\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Create the DataLoader for our validation set.\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "w2O5BeoE18xp"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = len(data.category.unique()), # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8gNpYoP19mM",
        "outputId": "b80c07ab-f7d5-4a7b-f9ee-d22b3ca09339"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = model.bert.pooler.dense.weight\n",
        "c = model.classifier.weight\n",
        "b = b.cpu().detach().numpy()\n",
        "c = c.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "pQ0QVTaQ2ERd"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all of the model's parameters as a list of tuples.\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA5ozcMA2HVS",
        "outputId": "86dc785c-9b5b-4957-b948-f9618e01dcc1"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (5, 768)\n",
            "classifier.bias                                                 (5,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "87ofgLxC2JWu"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs (authors recommend between 2 and 4)\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is number of batches * number of epochs.\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 100, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "30cTpHtf2M6v"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "X7BwiV772TLT"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "GTW09A_I2Xn9"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        # The call to `model` always returns a tuple, so we need to pull the \n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdE__l8i2ZxX",
        "outputId": "60b1fc4a-c780-4de4-9cc5-9bc762ddda3d"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:34.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:07.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:40.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:13.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:02:47.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:20.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:03:53.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:04:26.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:04:59.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:05:33.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:06.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:06:39.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:07:12.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:07:45.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:08:18.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:08:51.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:09:25.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:09:58.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:10:31.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:11:04.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:11:37.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:12:10.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:12:43.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:13:16.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:13:49.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:14:22.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:14:55.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:15:28.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:16:01.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:16:34.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:17:07.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:17:40.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:18:13.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:18:46.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:19:19.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:19:52.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:20:25.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:20:58.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:21:31.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:22:04.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:22:37.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:23:10.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:23:43.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:24:16.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:24:49.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:25:22.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:25:55.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:26:28.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:27:01.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:27:34.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:28:07.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:28:40.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:29:13.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:29:46.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:30:19.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:30:52.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:31:26.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:31:59.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:32:32.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:33:05.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:33:38.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:34:11.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:34:44.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:35:17.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:35:50.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:36:23.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:36:56.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:37:29.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:38:02.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:38:35.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:39:08.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:39:41.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:40:14.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:40:47.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:41:20.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:41:53.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:42:26.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:42:59.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:43:32.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:44:05.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:44:38.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:45:11.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:45:44.\n",
            "\n",
            "  Average training loss: 0.58\n",
            "  Training epcoh took: 0:46:03\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.84\n",
            "  Validation took: 0:01:45\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:06.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:38.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:11.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:02:44.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:17.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:03:50.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:04:22.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:04:55.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:05:28.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:01.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:06:34.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:07:07.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:07:39.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:08:12.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:08:45.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:09:18.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:09:51.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:10:24.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:10:56.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:11:29.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:12:02.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:12:35.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:13:08.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:13:41.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:14:14.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:14:47.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:15:20.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:15:53.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:16:26.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:16:59.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:17:32.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:18:05.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:18:38.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:19:11.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:19:44.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:20:17.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:20:50.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:21:23.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:21:56.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:22:29.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:23:02.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:23:35.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:24:08.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:24:41.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:25:14.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:25:47.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:26:20.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:26:53.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:27:26.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:27:59.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:28:32.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:29:05.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:29:38.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:30:11.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:30:44.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:31:18.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:31:51.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:32:24.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:32:57.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:33:30.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:34:03.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:34:36.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:35:09.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:35:42.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:36:15.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:36:48.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:37:21.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:37:54.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:38:27.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:39:00.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:39:33.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:40:06.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:40:39.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:41:12.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:41:45.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:42:18.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:42:51.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:43:24.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:43:57.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:44:30.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:45:04.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:45:37.\n",
            "\n",
            "  Average training loss: 0.40\n",
            "  Training epcoh took: 0:45:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:01:46\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:06.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:39.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:12.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:02:45.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:18.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:03:51.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:04:24.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:04:57.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:05:30.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:03.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:06:36.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:07:09.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:07:42.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:08:15.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:08:48.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:09:21.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:09:54.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:10:27.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:11:00.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:11:34.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:12:07.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:12:40.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:13:13.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:13:46.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:14:19.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:14:52.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:15:25.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:15:58.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:16:31.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:17:04.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:17:37.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:18:10.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:18:43.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:19:16.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:19:49.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:20:22.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:20:55.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:21:28.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:22:01.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:22:34.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:23:07.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:23:40.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:24:13.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:24:46.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:25:19.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:25:52.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:26:25.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:26:58.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:27:31.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:28:04.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:28:37.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:29:10.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:29:43.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:30:16.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:30:49.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:31:21.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:31:54.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:32:27.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:33:00.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:33:33.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:34:05.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:34:38.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:35:11.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:35:44.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:36:17.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:36:49.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:37:22.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:37:55.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:38:28.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:39:01.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:39:33.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:40:06.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:40:39.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:41:12.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:41:45.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:42:17.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:42:50.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:43:23.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:43:56.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:44:29.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:45:01.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:45:34.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:45:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:01:45\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  3,344.    Elapsed: 0:00:33.\n",
            "  Batch    80  of  3,344.    Elapsed: 0:01:06.\n",
            "  Batch   120  of  3,344.    Elapsed: 0:01:38.\n",
            "  Batch   160  of  3,344.    Elapsed: 0:02:11.\n",
            "  Batch   200  of  3,344.    Elapsed: 0:02:44.\n",
            "  Batch   240  of  3,344.    Elapsed: 0:03:17.\n",
            "  Batch   280  of  3,344.    Elapsed: 0:03:50.\n",
            "  Batch   320  of  3,344.    Elapsed: 0:04:22.\n",
            "  Batch   360  of  3,344.    Elapsed: 0:04:55.\n",
            "  Batch   400  of  3,344.    Elapsed: 0:05:28.\n",
            "  Batch   440  of  3,344.    Elapsed: 0:06:01.\n",
            "  Batch   480  of  3,344.    Elapsed: 0:06:34.\n",
            "  Batch   520  of  3,344.    Elapsed: 0:07:07.\n",
            "  Batch   560  of  3,344.    Elapsed: 0:07:39.\n",
            "  Batch   600  of  3,344.    Elapsed: 0:08:12.\n",
            "  Batch   640  of  3,344.    Elapsed: 0:08:45.\n",
            "  Batch   680  of  3,344.    Elapsed: 0:09:18.\n",
            "  Batch   720  of  3,344.    Elapsed: 0:09:51.\n",
            "  Batch   760  of  3,344.    Elapsed: 0:10:23.\n",
            "  Batch   800  of  3,344.    Elapsed: 0:10:56.\n",
            "  Batch   840  of  3,344.    Elapsed: 0:11:29.\n",
            "  Batch   880  of  3,344.    Elapsed: 0:12:02.\n",
            "  Batch   920  of  3,344.    Elapsed: 0:12:35.\n",
            "  Batch   960  of  3,344.    Elapsed: 0:13:07.\n",
            "  Batch 1,000  of  3,344.    Elapsed: 0:13:40.\n",
            "  Batch 1,040  of  3,344.    Elapsed: 0:14:13.\n",
            "  Batch 1,080  of  3,344.    Elapsed: 0:14:46.\n",
            "  Batch 1,120  of  3,344.    Elapsed: 0:15:19.\n",
            "  Batch 1,160  of  3,344.    Elapsed: 0:15:52.\n",
            "  Batch 1,200  of  3,344.    Elapsed: 0:16:24.\n",
            "  Batch 1,240  of  3,344.    Elapsed: 0:16:57.\n",
            "  Batch 1,280  of  3,344.    Elapsed: 0:17:30.\n",
            "  Batch 1,320  of  3,344.    Elapsed: 0:18:03.\n",
            "  Batch 1,360  of  3,344.    Elapsed: 0:18:36.\n",
            "  Batch 1,400  of  3,344.    Elapsed: 0:19:08.\n",
            "  Batch 1,440  of  3,344.    Elapsed: 0:19:41.\n",
            "  Batch 1,480  of  3,344.    Elapsed: 0:20:14.\n",
            "  Batch 1,520  of  3,344.    Elapsed: 0:20:47.\n",
            "  Batch 1,560  of  3,344.    Elapsed: 0:21:20.\n",
            "  Batch 1,600  of  3,344.    Elapsed: 0:21:53.\n",
            "  Batch 1,640  of  3,344.    Elapsed: 0:22:25.\n",
            "  Batch 1,680  of  3,344.    Elapsed: 0:22:58.\n",
            "  Batch 1,720  of  3,344.    Elapsed: 0:23:31.\n",
            "  Batch 1,760  of  3,344.    Elapsed: 0:24:04.\n",
            "  Batch 1,800  of  3,344.    Elapsed: 0:24:37.\n",
            "  Batch 1,840  of  3,344.    Elapsed: 0:25:10.\n",
            "  Batch 1,880  of  3,344.    Elapsed: 0:25:43.\n",
            "  Batch 1,920  of  3,344.    Elapsed: 0:26:15.\n",
            "  Batch 1,960  of  3,344.    Elapsed: 0:26:48.\n",
            "  Batch 2,000  of  3,344.    Elapsed: 0:27:21.\n",
            "  Batch 2,040  of  3,344.    Elapsed: 0:27:54.\n",
            "  Batch 2,080  of  3,344.    Elapsed: 0:28:27.\n",
            "  Batch 2,120  of  3,344.    Elapsed: 0:29:00.\n",
            "  Batch 2,160  of  3,344.    Elapsed: 0:29:33.\n",
            "  Batch 2,200  of  3,344.    Elapsed: 0:30:05.\n",
            "  Batch 2,240  of  3,344.    Elapsed: 0:30:38.\n",
            "  Batch 2,280  of  3,344.    Elapsed: 0:31:11.\n",
            "  Batch 2,320  of  3,344.    Elapsed: 0:31:44.\n",
            "  Batch 2,360  of  3,344.    Elapsed: 0:32:17.\n",
            "  Batch 2,400  of  3,344.    Elapsed: 0:32:50.\n",
            "  Batch 2,440  of  3,344.    Elapsed: 0:33:22.\n",
            "  Batch 2,480  of  3,344.    Elapsed: 0:33:55.\n",
            "  Batch 2,520  of  3,344.    Elapsed: 0:34:28.\n",
            "  Batch 2,560  of  3,344.    Elapsed: 0:35:01.\n",
            "  Batch 2,600  of  3,344.    Elapsed: 0:35:34.\n",
            "  Batch 2,640  of  3,344.    Elapsed: 0:36:06.\n",
            "  Batch 2,680  of  3,344.    Elapsed: 0:36:39.\n",
            "  Batch 2,720  of  3,344.    Elapsed: 0:37:12.\n",
            "  Batch 2,760  of  3,344.    Elapsed: 0:37:45.\n",
            "  Batch 2,800  of  3,344.    Elapsed: 0:38:17.\n",
            "  Batch 2,840  of  3,344.    Elapsed: 0:38:50.\n",
            "  Batch 2,880  of  3,344.    Elapsed: 0:39:23.\n",
            "  Batch 2,920  of  3,344.    Elapsed: 0:39:56.\n",
            "  Batch 2,960  of  3,344.    Elapsed: 0:40:29.\n",
            "  Batch 3,000  of  3,344.    Elapsed: 0:41:02.\n",
            "  Batch 3,040  of  3,344.    Elapsed: 0:41:34.\n",
            "  Batch 3,080  of  3,344.    Elapsed: 0:42:07.\n",
            "  Batch 3,120  of  3,344.    Elapsed: 0:42:40.\n",
            "  Batch 3,160  of  3,344.    Elapsed: 0:43:13.\n",
            "  Batch 3,200  of  3,344.    Elapsed: 0:43:46.\n",
            "  Batch 3,240  of  3,344.    Elapsed: 0:44:19.\n",
            "  Batch 3,280  of  3,344.    Elapsed: 0:44:51.\n",
            "  Batch 3,320  of  3,344.    Elapsed: 0:45:24.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:45:44\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  Validation took: 0:01:45\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w2cl9gSci-OM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "YN4gm_mX2hUS",
        "outputId": "0d80004f-3fad-41f3-c7bf-217eb1284a05"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "#df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(data2.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = data2.text.values\n",
        "labels = data2.category.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                   )\n",
        "    \n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "# Pad our input tokens\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
        "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask) \n",
        "\n",
        "# Convert to tensors.\n",
        "prediction_inputs = torch.tensor(input_ids)\n",
        "prediction_masks = torch.tensor(attention_masks)\n",
        "prediction_labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "al29blzd2k7F"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PmJt6cqkW-BW"
      ],
      "name": "QuesT_Homework3_classification_(2)_(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}